{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d3d204-5a28-4c99-a99d-a26be1dfcd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72078927-4c76-459d-9e49-97a591db62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"data/california.csv\", skip_blank_lines=True, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93e8cfd-701c-43cd-afc5-400aedd52265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.set_axis(['First', 'Name', 'Date', 'Victims', 'Location'], axis=1)\n",
    "df_all = df_all.drop(\"First\", axis = 1)\n",
    "df_all = df_all[df_all['Victims'].notna()]\n",
    "df_all['Victims'] = df_all['Victims'].str.replace('+', '', regex=False).str.replace('?','', regex=False).str.extract(r'(\\d+)')\n",
    "df_all.Victims = pd.to_numeric(df_all.Victims, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9704eb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Victims</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burton W. ABBOTT</td>\n",
       "      <td>April 28, 1955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>California, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert James ACREMANT</td>\n",
       "      <td>Oct./Dec. 1995</td>\n",
       "      <td>3.0</td>\n",
       "      <td>California, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph Moreno AGUAYO</td>\n",
       "      <td>April 17, 1979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>California, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rodney James ALCALA</td>\n",
       "      <td>1977 - 1979</td>\n",
       "      <td>5.0</td>\n",
       "      <td>California, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Andre ALEXANDER</td>\n",
       "      <td>1978 / 1980</td>\n",
       "      <td>4.0</td>\n",
       "      <td>California, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name            Date  Victims         Location\n",
       "1       Burton W. ABBOTT  April 28, 1955      1.0  California, USA\n",
       "2  Robert James ACREMANT  Oct./Dec. 1995      3.0  California, USA\n",
       "3   Joseph Moreno AGUAYO  April 17, 1979      1.0  California, USA\n",
       "4    Rodney James ALCALA     1977 - 1979      5.0  California, USA\n",
       "5        Andre ALEXANDER     1978 / 1980      4.0  California, USA"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b04efef-d3c6-4f2d-bcc9-b4267c557bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links = pd.read_csv(\"links/california.csv\", skip_blank_lines=True, encoding='unicode_escape', header=None)\n",
    "df_links = df_links.set_axis(['Link'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4245cb-9a32-4903-aa5a-8223e1a07744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://murderpedia.org/male.A/a/abbott-burton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://murderpedia.org/male.A/a/acremant-robe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://murderpedia.org/male.A/a/aguayo-joseph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://murderpedia.org/male.A/a/alcala-rodney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://murderpedia.org/male.A/a/alexander-and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link\n",
       "0  https://murderpedia.org/male.A/a/abbott-burton...\n",
       "1  https://murderpedia.org/male.A/a/acremant-robe...\n",
       "2  https://murderpedia.org/male.A/a/aguayo-joseph...\n",
       "3  https://murderpedia.org/male.A/a/alcala-rodney...\n",
       "4  https://murderpedia.org/male.A/a/alexander-and..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25dd650d-4b72-4d67-9ef0-5307da5c9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(row):\n",
    "    return (row['Link'].split(\"/\")[-1].replace(\".htm\", \"\").split(\"-\")[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26e05754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://murderpedia.org/male.A/a/abbott-burton...</td>\n",
       "      <td>[burton, abbott]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://murderpedia.org/male.A/a/acremant-robe...</td>\n",
       "      <td>[robert, acremant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://murderpedia.org/male.A/a/aguayo-joseph...</td>\n",
       "      <td>[joseph, aguayo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://murderpedia.org/male.A/a/alcala-rodney...</td>\n",
       "      <td>[rodney, alcala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://murderpedia.org/male.A/a/alexander-and...</td>\n",
       "      <td>[andre, alexander]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link                Name\n",
       "0  https://murderpedia.org/male.A/a/abbott-burton...    [burton, abbott]\n",
       "1  https://murderpedia.org/male.A/a/acremant-robe...  [robert, acremant]\n",
       "2  https://murderpedia.org/male.A/a/aguayo-joseph...    [joseph, aguayo]\n",
       "3  https://murderpedia.org/male.A/a/alcala-rodney...    [rodney, alcala]\n",
       "4  https://murderpedia.org/male.A/a/alexander-and...  [andre, alexander]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_links['Name'] = df_links.apply(get_name, axis=1)\n",
    "df_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8585af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_names(row):\n",
    "    return (row['Name'].lower().split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77e2ba2-6ca4-429f-9246-b9bda076d361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Victims</th>\n",
       "      <th>Location</th>\n",
       "      <th>Broken_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Kao XIONG</td>\n",
       "      <td>December 4, 1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>[kao, xiong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Gourgen Mkrtich YANIKIAN</td>\n",
       "      <td>January 27, 1973</td>\n",
       "      <td>2.0</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>[gourgen, mkrtich, yanikian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Leung YING</td>\n",
       "      <td>August 22, 1928</td>\n",
       "      <td>11.0</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>[leung, ying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>William Floyd ZAMASTIL</td>\n",
       "      <td>1978</td>\n",
       "      <td>3.0</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>[william, floyd, zamastil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>John ZAWAHRI</td>\n",
       "      <td>June 7, 2013</td>\n",
       "      <td>5.0</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>[john, zawahri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name              Date  Victims         Location  \\\n",
       "383                 Kao XIONG  December 4, 1999      5.0  California, USA   \n",
       "385  Gourgen Mkrtich YANIKIAN  January 27, 1973      2.0  California, USA   \n",
       "386                Leung YING   August 22, 1928     11.0  California, USA   \n",
       "388    William Floyd ZAMASTIL              1978      3.0  California, USA   \n",
       "389              John ZAWAHRI      June 7, 2013      5.0  California, USA   \n",
       "\n",
       "                     Broken_names  \n",
       "383                  [kao, xiong]  \n",
       "385  [gourgen, mkrtich, yanikian]  \n",
       "386                 [leung, ying]  \n",
       "388    [william, floyd, zamastil]  \n",
       "389               [john, zawahri]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"Broken_names\"] = df_all.apply(break_names, axis = 1)\n",
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "755f924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/rf89nwnj6q56gl1nssrbv4380000gn/T/ipykernel_42913/256205555.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_final = pd.concat([pd.DataFrame([[row1[\"Name\"], row1[\"Date\"], row2[\"Link\"], row1[\"Victims\"], row1[\"Location\"]]], columns=df_final.columns), df_final], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame(columns=['Name', 'Date', 'Link', 'Victims', 'Location'])\n",
    "for (i, row1), (j, row2) in zip(df_all.iterrows(), df_links.iterrows()):\n",
    "    if fuzz.ratio(row1[\"Broken_names\"], row2[\"Name\"]) > 50:\n",
    "        df_final = pd.concat([pd.DataFrame([[row1[\"Name\"], row1[\"Date\"], row2[\"Link\"], row1[\"Victims\"], row1[\"Location\"]]], columns=df_final.columns), df_final], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a48b6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['Victims'] >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebea8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c5e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_names(row):\n",
    "    return (row['Name'].lower().split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8d7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(row):\n",
    "    return (row['Link'].split(\"/\")[-1].replace(\".htm\", \"\").split(\"-\")[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4931dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataframe(file_name):\n",
    "    df_all = pd.read_csv(file_name, skip_blank_lines=True, encoding='unicode_escape').drop_duplicates()\n",
    "    df_all = df_all.set_axis(['First', 'Name', 'Date', 'Victims', 'Location'], axis=1)\n",
    "    df_all = df_all.drop('First', axis = 1)\n",
    "    df_all = df_all[df_all['Victims'].notna()]\n",
    "    df_all['Victims'] = df_all['Victims'].str.replace('+', '', regex=False)\\\n",
    "        .str.replace('?','', regex=False).str.extract(r'(\\d+)')\n",
    "    df_all.Victims = pd.to_numeric(df_all.Victims, errors='coerce')\n",
    "    df_all[\"Broken_names\"] = df_all.apply(break_names, axis = 1)\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ebe8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_dataframe(link_file_name):\n",
    "    df_links = pd.read_csv(str(\"links/\" + link_file_name), encoding='unicode_escape')\n",
    "    df_links = df_links.set_axis(['Link'], axis=1)\n",
    "    df_links['Name'] = df_links.apply(get_name, axis=1)\n",
    "\n",
    "    return df_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f0d30e-334d-479a-b833-1bbbcffd3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv():\n",
    "    print(\"Combining CSV's START\")\n",
    "    writer = pd.ExcelWriter('CompleteFiles/Serial_Killers.xlsx')\n",
    "    i = 0\n",
    "    for file_name in glob.glob(\"data/*.csv\"):\n",
    "        i += 1\n",
    "        # Process Dataframe with all the Data\n",
    "        df_all = get_all_dataframe(file_name)\n",
    "\n",
    "        link_file_name = file_name.split(\"/\")[1]\n",
    "        # Process Dataframe with the Links\n",
    "        df_links = get_links_dataframe(link_file_name)\n",
    "        \n",
    "        # Combine both dataframes based on fuzzy comparison of the Names\n",
    "        df_final = pd.DataFrame(columns=['Name', 'Date', 'Link', 'Victims', 'Location'])\n",
    "        for (i, row1) in df_all.iterrows():\n",
    "            for (j, row2) in df_links.iterrows():\n",
    "                if fuzz.ratio(row1[\"Broken_names\"], row2[\"Name\"]) > 50:\n",
    "                    df_final = pd.concat([pd.DataFrame([[row1[\"Name\"], row1[\"Date\"], row2[\"Link\"], row1[\"Victims\"], row1[\"Location\"]]], columns=df_final.columns), df_final], ignore_index=True)\n",
    "                    df_links.drop(index=[j])\n",
    "                    break\n",
    "        \n",
    "        print(df_final.head())\n",
    "        # Remove all rows with less than 3 victims as Serial Killers are >= 3\n",
    "        df_final = df_final[df_final['Victims'] >= 3]\n",
    "        sheet_name = file_name.split(\"/\")[1].replace(\".csv\",\"\").capitalize()\n",
    "        df_final.to_excel(writer,sheet_name=sheet_name)\n",
    "    writer._save()\n",
    "    print(i, \" CSV's combined into Serial_Killers.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51264ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining CSV's START\n",
      "                    Name                Date  Victims      Location  \\\n",
      "1      Joseph Dewey AKIN         1990 - 1991     18.0  Georgia, USA   \n",
      "2   Jack Edward ALDERMAN  September 21, 1974      1.0  Georgia, USA   \n",
      "3   Stanley Edward ALLEN     January 5, 1981      1.0  Georgia, USA   \n",
      "4  James Douglas ANDREWS       July 23, 1990      1.0  Georgia, USA   \n",
      "6   Clinton BANKSTON Jr.   April/August 1987      5.0  Georgia, USA   \n",
      "\n",
      "                Broken_names  \n",
      "1      [joseph, dewey, akin]  \n",
      "2   [jack, edward, alderman]  \n",
      "3   [stanley, edward, allen]  \n",
      "4  [james, douglas, andrews]  \n",
      "6   [clinton, bankston, jr.]  \n",
      "196\n",
      "                                                Link  \\\n",
      "0  https://murderpedia.org/male.A/a1/alderman-jac...   \n",
      "1  https://murderpedia.org/male.A/a/allen-stanley...   \n",
      "2  https://murderpedia.org/male.A/a/andrews-james...   \n",
      "3  https://murderpedia.org/male.B/b/bankston-clin...   \n",
      "4  https://murderpedia.org/male.B/b/barnes-joseph...   \n",
      "\n",
      "                        Name  \n",
      "0           [jack, alderman]  \n",
      "1   [edward, stanley, allen]  \n",
      "2  [douglas, james, andrews]  \n",
      "3        [clinton, bankston]  \n",
      "4   [martin, joseph, barnes]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/rf89nwnj6q56gl1nssrbv4380000gn/T/ipykernel_47348/3583338029.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_final = pd.concat([pd.DataFrame([[row1[\"Name\"], row1[\"Date\"], row2[\"Link\"], row1[\"Victims\"], row1[\"Location\"]]], columns=df_final.columns), df_final], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Name              Date  \\\n",
      "0  George Martin ZINKHAN III    April 25, 2009   \n",
      "1              John C. YOUNG  December 7, 1974   \n",
      "2     Thomas George WOOLFOLK    August 6, 1887   \n",
      "3           Andrew Paul WITT      July 5, 2004   \n",
      "4                 Henry WIRZ       1864 - 1865   \n",
      "\n",
      "                                                Link  Victims      Location  \n",
      "0  https://murderpedia.org/male.Z/z/zinkhan-georg...      3.0  Georgia, USA  \n",
      "1   https://murderpedia.org/male.Y/y1/young-john.htm      3.0  Georgia, USA  \n",
      "2  https://murderpedia.org/male.W/w/woolfolk-thom...      9.0  Georgia, USA  \n",
      "3  https://murderpedia.org/male.W/w/witt-andrew-p...      2.0  Georgia, USA  \n",
      "4    https://murderpedia.org/male.W/w/wirz-henry.htm     11.0  Georgia, USA  \n",
      "georgia.csv 44\n",
      "                    Name              Date  Victims             Location  \\\n",
      "1  Sylvester Lewis ADAMS  October 17, 1979        1  South Carolina, USA   \n",
      "2     Quincy Javon ALLEN  July-August 2002        4  South Carolina, USA   \n",
      "3         John D. ARNOLD    April 12, 1978        1  South Carolina, USA   \n",
      "4   Joseph Ernest ATKINS       1985 / 1999        3  South Carolina, USA   \n",
      "6        Larry Gene BELL     May-June 1985        2  South Carolina, USA   \n",
      "\n",
      "                Broken_names  \n",
      "1  [sylvester, lewis, adams]  \n",
      "2     [quincy, javon, allen]  \n",
      "3         [john, d., arnold]  \n",
      "4   [joseph, ernest, atkins]  \n",
      "6        [larry, gene, bell]  \n",
      "74\n",
      "                                                Link                      Name\n",
      "0  https://murderpedia.org/male.A/a/allen-quincy-...    [javon, quincy, allen]\n",
      "1  https://murderpedia.org/male.A/a1/arnold-john.htm            [john, arnold]\n",
      "2  https://murderpedia.org/male.A/a1/atkins-josep...  [ernest, joseph, atkins]\n",
      "3  https://murderpedia.org/male.B/b1/bell-larry-g...       [gene, larry, bell]\n",
      "4  https://murderpedia.org/male.B/b/bounds-dallen...          [dallen, bounds]\n",
      "                    Name                Date  \\\n",
      "0       Kevin Dean YOUNG     August 31, 1988   \n",
      "1      Dale Robert YATES   February 12, 1981   \n",
      "2  Ronald Raymond WOOMER       February 1979   \n",
      "3   Hastings Arthur WISE  September 15, 1997   \n",
      "4   Luke A. WILLIAMS III       June 19, 1991   \n",
      "\n",
      "                                                Link Victims  \\\n",
      "0  https://murderpedia.org/male.Y/y1/young-kevin-...       1   \n",
      "1  https://murderpedia.org/male.Y/y/yates-dale-ro...       1   \n",
      "2  https://murderpedia.org/male.W/w1/woomer-ronal...       4   \n",
      "3  https://murderpedia.org/male.W/w1/wise-hasting...       4   \n",
      "4  https://murderpedia.org/male.W/w1/williams-luk...       2   \n",
      "\n",
      "              Location  \n",
      "0  South Carolina, USA  \n",
      "1  South Carolina, USA  \n",
      "2  South Carolina, USA  \n",
      "3  South Carolina, USA  \n",
      "4  South Carolina, USA  \n",
      "south-carolina.csv 31\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mcombine_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mcombine_csv\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Process Dataframe with all the Data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_all \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_all))\n\u001b[1;32m     11\u001b[0m link_file_name \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mget_all_dataframe\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m df_all \u001b[38;5;241m=\u001b[39m df_all\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m df_all \u001b[38;5;241m=\u001b[39m df_all[df_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVictims\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\n\u001b[0;32m----> 6\u001b[0m df_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVictims\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_all\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVictims\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m df_all\u001b[38;5;241m.\u001b[39mVictims \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df_all\u001b[38;5;241m.\u001b[39mVictims, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m df_all[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroken_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_all\u001b[38;5;241m.\u001b[39mapply(break_names, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6297\u001b[0m ):\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/strings/accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/strings/accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    combine_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6eb48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
